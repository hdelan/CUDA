\documentclass[a4paper, fleqn]{article}

\date{\today}
\author{Hugh Delaney}
\title{5615 CUDA---Assignment 3 \\ Exponential Integral Calculation}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools, geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\usepackage{xcolor}
\usepackage{listings}

\DeclarePairedDelimiterX{\inp}[2]{\langle}{\rangle}{#1, #2}

\setlength{\mathindent}{1cm}

% figure support
\usepackage{import}
\usepackage{xifthen}
\pdfminorversion=7
\usepackage{pdfpages}
\usepackage{caption, subcaption}
\usepackage{transparent}
\newcommand{\incfig}[1]{%
        \def\svgwidth{\columnwidth}
        \import{./figures/}{#1.pdf_tex}
}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}



\pdfsuppresswarningpagegroup=1

\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{proposition}{Proposition}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}{Lemma}[theorem]

\renewcommand\qedsymbol{$\blacksquare$}

\begin{document}
\maketitle
        \section{CUDA Implementation}%
        \label{sec:cuda_implementation}
        
        Please see \texttt{gpu\_funcs.cu}.

        Advanced techniques used:
        \begin{itemize}
                \item Constant/Shared memory---constant memory was used in the first implementations, but it was markedly slower than initializing shared memory with hard coded values. The final implementation uses shared memory as a fast alternative to constant memory.
                \item Multiple Cards/Streams---Multiple cards are used if you provide the \texttt{-s} option. This gives a real boost to performance, especially due to using \texttt{cudaMemcpyAsync()}, which allows memory transfer on one card to overlap with computation on the other card. \texttt{make run2} will run the code on two cards and report individual timings for each card. Since streams are understood to be launched simultaneously, we can take the overall run time as the greater of the two individual timings. 
        \end{itemize}

        Advanced techniques considered:
        \begin{itemize}
                \item Texture memory---Texture memory was considered so that we could index between a and b with floating point indexes. However this was decided against since the overhead of creating and initializing texture memory outweighed the cost of creating x values in kernel, which requires no cudaMemcpys before the kernel can start.
                \item Dynamic Parallelism---Potential approach of launching one thread per n value, and precomputing \texttt{psi} (if \texttt{a<=1.0}), before launching enough threads/blocks to compute the \texttt{numberOfSamples} x values from \texttt{a} to \texttt{b} for that given value of \texttt{n}. 
        \end{itemize}
\section{Performance}%
\label{sec:performance}


\end{document}
